<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Practical exam</title>

<script src="site_libs/header-attrs-2.29/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/paper.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Richard W Morris</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
<li>
  <a href="rcode.html">R examples</a>
</li>
<li>
  <a href="CV.pdf">CV</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Practical exam</h1>

</div>


<p><font size="3"></p>
<hr />
<div id="task" class="section level1">
<h1>Task</h1>
<p>You have been asked to evaluate a numeracy program that is provided
to Year 3 students in NSW government schools. You are required to:</p>
<ul>
<li>interpret the results from an analysis on the short-term impact of
the program; and</li>
<li>evaluate the long-term impact of the program.</li>
</ul>
<div id="about-the-program" class="section level2">
<h2>About the program</h2>
<p>The program was designed to improve numeracy proficiency and is a
whole-of-school intervention. All Year 3 students in participating
schools participate in the program at the beginning of the school year
in 2018.</p>
<p><br></p>
</div>
<div id="task-1-interpretation-of-results-from-an-analysis"
class="section level2">
<h2>Task 1 Interpretation of results from an analysis</h2>
<p>You undertake a statistical analysis of the impact of the program
using a Hierarchical Linear Modelling (HLM) technique. The model has a
two-level structure with students (level-1) nested within schools
(level-2). Table 1 (on page 2) shows the output from the HLM analysis,
using the student data from 2018 to 2019.</p>
<p>The dependent variable in the model was Year 4 Numeracy results. The
model included the following school-level variables:</p>
<ul>
<li>a <strong>treatment</strong> indicator (a binary variable taking the
value 1 when a school was using the program and 0 otherwise);</li>
<li>a <strong>SES</strong> variable (a continuous measure of school
socio-economic status; higher value indicates higher socio-economic
status); and</li>
<li>a <strong>relative school growth</strong> variable (a school growth
score for each school was first calculated as the mean Year 4 scores
minus the mean Year 3 scores). The relative school growth variable was
then calculated as the deviation from the grand mean of the school
growth scores).</li>
</ul>
<p>The model also included the following student-level variables:</p>
<ul>
<li><strong>Year 3 Numeracy scores</strong> (a continuous measure of
numeracy performance in Year 3 <strong><em>PRIOR</em></strong> to the
intervention);</li>
<li><strong>First Nations status</strong> (a binary variable taking the
value 1 for First-Nations students and 0 otherwise);</li>
<li><strong>Gender</strong> (a binary variable taking the value 1 when a
student was female and 0 otherwise);</li>
<li><strong>Language background</strong> (a binary variable taking the
value 1 when a student had a language background other than English and
0 otherwise).</li>
</ul>
<p><br></p>
<div
id="table-1-results-of-hlm-analysis-with-year-4-numeracy-score-as-dependent-variable"
class="section level3">
<h3>Table 1: Results of HLM analysis, with Year 4 Numeracy score as
dependent variable</h3>
<div class="kable-table">
<table>
<colgroup>
<col width="32%" />
<col width="22%" />
<col width="14%" />
<col width="9%" />
<col width="9%" />
<col width="11%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Model</th>
<th align="right">Coefficient (B)</th>
<th align="right">Std Error</th>
<th align="right">Beta</th>
<th align="right">t</th>
<th align="right">p-value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Constant</td>
<td align="right">92.011</td>
<td align="right">28.832</td>
<td align="right">1.000</td>
<td align="right">3.191</td>
<td align="right">0.001</td>
</tr>
<tr class="even">
<td align="left">Relative school growth</td>
<td align="right">0.884</td>
<td align="right">0.069</td>
<td align="right">0.246</td>
<td align="right">12.757</td>
<td align="right">0.000</td>
</tr>
<tr class="odd">
<td align="left">Year 3 Numeracy</td>
<td align="right">0.741</td>
<td align="right">0.020</td>
<td align="right">0.711</td>
<td align="right">36.756</td>
<td align="right">0.000</td>
</tr>
<tr class="even">
<td align="left">SES</td>
<td align="right">0.065</td>
<td align="right">0.022</td>
<td align="right">0.066</td>
<td align="right">3.003</td>
<td align="right">0.003</td>
</tr>
<tr class="odd">
<td align="left">Gender</td>
<td align="right">5.216</td>
<td align="right">2.703</td>
<td align="right">0.035</td>
<td align="right">1.930</td>
<td align="right">0.054</td>
</tr>
<tr class="even">
<td align="left">First Nations status</td>
<td align="right">-17.001</td>
<td align="right">6.108</td>
<td align="right">-0.053</td>
<td align="right">-2.783</td>
<td align="right">0.005</td>
</tr>
<tr class="odd">
<td align="left">Language Background</td>
<td align="right">0.107</td>
<td align="right">1.649</td>
<td align="right">0.001</td>
<td align="right">0.065</td>
<td align="right">0.948</td>
</tr>
<tr class="even">
<td align="left">Treatment</td>
<td align="right">4.126</td>
<td align="right">3.070</td>
<td align="right">0.256</td>
<td align="right">1.344</td>
<td align="right">0.179</td>
</tr>
</tbody>
</table>
</div>
<p><br></p>
</div>
<div id="what-are-the-assumptions-of-the-model-described-above"
class="section level3">
<h3>What are the assumptions of the model described above?</h3>
<p>The aim of the model was to evaluate the (short-term) impact of the
program. The most important assumption of the model is there were no
pre-existing differences between the program and non-program schools.
I.e., any differences were random (which can be assumed when schools
were randomly allocated to treatment arms).</p>
<p>When pre-existing differences exist, interpreting the impact of the
program (Treatment <span class="math inline">\(\beta\)</span>) on Year 4
scores is not straightfoward. This model adjusted for pre-existing
differences by including Year 3 scores, which produces an estimate of
the Year 4 differences among children <em>with the same Year 3 numeracy
levels</em>. However if (as is likely) schools with low numeracy
students were more likely to be allocated to the program then this
assumption is not warranted, and the treatment <span
class="math inline">\(\beta\)</span> will underestimate the total impact
of the program on numeracy levels at Year 4, due to
regression-to-the-mean effects (RTM). The RTM effects occur because
equating Year 3 scores is similar to selecting <em>above average</em>
students in poor schools for treatment and <em>below average</em>
students in good schools as comparisons, which will result in smaller
than expected <em>Year 4 differences</em> after each group regresses to
their respective group means. In this way, conditional treatment effects
can be biased and in some cases underestimate the true effect.</p>
<p>However after random allocation, interpreting the Treatment <span
class="math inline">\(\beta\)</span> in the presence of pre-existing
differences is straightforward, as all differences between schools
<strong>not due to treatment</strong> are random: Adjusting for
pre-existing differences is warranted and the adjusted Treatment <span
class="math inline">\(\beta\)</span> will not be biased (and be more
precise).</p>
<p><em>Nb.</em> The <em>Relative school growth</em> score represents the
relative change for each school, and so adjusts for differences in
growth between each school - that is the clustered changes (among
students) due to school rather than treatment. However it seems likely
to covary with any school-level treatment effect, which is likely to
confound <span class="math inline">\(\tau\)</span> (when included in my
experiments in the analyses below I cannot replicate the results
provided).</p>
<p><br></p>
</div>
<div
id="what-diagnostics-could-you-use-to-check-the-fit-of-the-model-and-whether-the-assumptions-of-the-model-are-valid"
class="section level3">
<h3>What diagnostics could you use to check the fit of the model and
whether the assumptions of the model are valid?</h3>
<p>There is no way to test whether allocation to the program was random;
testing for significant differences in Year 3 numeracy between the
treatment groups can tell us if pre-existing differences were present
but will not help us determine whether those differences were due to a
systematic effect or random variation (sometimes random allocation
results in significant differences between groups - in which case the
average treatment effect is unbiased <em>in the long run</em>).</p>
<p>However we can assess whether pre-existing differences in Year 3
numeracy are present, which will indicate how well-matched the treatment
groups were, and may also reveal whether RTM effects were likely.</p>
<p>Let’s take a look at the data</p>
<div class="kable-table">
<table style="width:100%;">
<colgroup>
<col width="10%" />
<col width="11%" />
<col width="11%" />
<col width="9%" />
<col width="7%" />
<col width="14%" />
<col width="20%" />
<col width="5%" />
<col width="10%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">School_ID</th>
<th align="right">Student_ID</th>
<th align="right">Year_level</th>
<th align="right">Numeracy</th>
<th align="right">Gender</th>
<th align="right">First_Nations</th>
<th align="right">Language_background</th>
<th align="right">SES</th>
<th align="left">Treatment</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1100067</td>
<td align="right">1</td>
<td align="right">3</td>
<td align="right">464.3</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1159</td>
<td align="left">0</td>
</tr>
<tr class="even">
<td align="left">1100067</td>
<td align="right">1</td>
<td align="right">4</td>
<td align="right">542.7</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1159</td>
<td align="left">0</td>
</tr>
<tr class="odd">
<td align="left">1100067</td>
<td align="right">1</td>
<td align="right">5</td>
<td align="right">531.1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1159</td>
<td align="left">0</td>
</tr>
<tr class="even">
<td align="left">1100067</td>
<td align="right">1</td>
<td align="right">6</td>
<td align="right">554.9</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1159</td>
<td align="left">0</td>
</tr>
<tr class="odd">
<td align="left">1100044</td>
<td align="right">2</td>
<td align="right">3</td>
<td align="right">258.1</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1064</td>
<td align="left">1</td>
</tr>
<tr class="even">
<td align="left">1100044</td>
<td align="right">2</td>
<td align="right">4</td>
<td align="right">387.2</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1064</td>
<td align="left">1</td>
</tr>
<tr class="odd">
<td align="left">1100044</td>
<td align="right">2</td>
<td align="right">5</td>
<td align="right">428.1</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1064</td>
<td align="left">1</td>
</tr>
<tr class="even">
<td align="left">1100044</td>
<td align="right">2</td>
<td align="right">6</td>
<td align="right">542.3</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1064</td>
<td align="left">1</td>
</tr>
<tr class="odd">
<td align="left">1100044</td>
<td align="right">3</td>
<td align="right">3</td>
<td align="right">352.5</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1064</td>
<td align="left">1</td>
</tr>
<tr class="even">
<td align="left">1100044</td>
<td align="right">3</td>
<td align="right">4</td>
<td align="right">456.7</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1064</td>
<td align="left">1</td>
</tr>
</tbody>
</table>
</div>
<p>The records are arranged in long format with rows arranged by school,
student and year; and each row representing a student-year
observation.</p>
<p>For Task 1, we will select the data from Years 3 and 4, and rearrange
it into wide format with <code>Pre</code> and <code>Post</code>
scores.</p>
<div class="kable-table">
<table style="width:100%;">
<colgroup>
<col width="11%" />
<col width="12%" />
<col width="7%" />
<col width="15%" />
<col width="22%" />
<col width="5%" />
<col width="11%" />
<col width="6%" />
<col width="6%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">School_ID</th>
<th align="right">Student_ID</th>
<th align="right">Gender</th>
<th align="right">First_Nations</th>
<th align="right">Language_background</th>
<th align="right">SES</th>
<th align="left">Treatment</th>
<th align="right">Pre</th>
<th align="right">Post</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1100021</td>
<td align="right">41</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1180</td>
<td align="left">1</td>
<td align="right">358.9</td>
<td align="right">507.9</td>
</tr>
<tr class="even">
<td align="left">1100021</td>
<td align="right">59</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1180</td>
<td align="left">1</td>
<td align="right">467.0</td>
<td align="right">571.2</td>
</tr>
<tr class="odd">
<td align="left">1100021</td>
<td align="right">61</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1180</td>
<td align="left">1</td>
<td align="right">493.2</td>
<td align="right">529.4</td>
</tr>
<tr class="even">
<td align="left">1100021</td>
<td align="right">62</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1180</td>
<td align="left">1</td>
<td align="right">361.1</td>
<td align="right">421.1</td>
</tr>
<tr class="odd">
<td align="left">1100021</td>
<td align="right">67</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1180</td>
<td align="left">1</td>
<td align="right">413.1</td>
<td align="right">523.9</td>
</tr>
<tr class="even">
<td align="left">1100021</td>
<td align="right">68</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1180</td>
<td align="left">1</td>
<td align="right">378.6</td>
<td align="right">435.1</td>
</tr>
<tr class="odd">
<td align="left">1100021</td>
<td align="right">69</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1180</td>
<td align="left">1</td>
<td align="right">405.7</td>
<td align="right">420.7</td>
</tr>
<tr class="even">
<td align="left">1100021</td>
<td align="right">70</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1180</td>
<td align="left">1</td>
<td align="right">359.0</td>
<td align="right">416.7</td>
</tr>
<tr class="odd">
<td align="left">1100021</td>
<td align="right">74</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1180</td>
<td align="left">1</td>
<td align="right">429.1</td>
<td align="right">502.5</td>
</tr>
<tr class="even">
<td align="left">1100021</td>
<td align="right">76</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1180</td>
<td align="left">1</td>
<td align="right">563.5</td>
<td align="right">599.3</td>
</tr>
</tbody>
</table>
</div>
<p><br></p>
<p>Pre-existing numeracy differences between groups were present,
indicating the groups were not well-matched and consistent with the
likely presence of RTM effects:</p>
<pre class="r"><code>df %&gt;%
  filter(Year_level == 3) %&gt;%
  lm(Numeracy ~ 1 + Treatment, 
     data = .) %&gt;%
  tidy()</code></pre>
<div class="kable-table">
<table>
<thead>
<tr class="header">
<th align="left">term</th>
<th align="right">estimate</th>
<th align="right">std.error</th>
<th align="right">statistic</th>
<th align="right">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">(Intercept)</td>
<td align="right">422.70</td>
<td align="right">2.204</td>
<td align="right">191.76</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">Treatment1</td>
<td align="right">-31.18</td>
<td align="right">3.113</td>
<td align="right">-10.02</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
</div>
<p>The intercept of <strong>423</strong> is the mean numeracy level
among the non-program schools in Year 3, while the estimate for the
treatment effect of <strong>-31.2 (p &lt; .001)</strong> represents a
significant pre-existing deficit in numeracy scores among the program
schools.</p>
<pre class="r"><code># Adding further controls does not remove the pre-existing difference:

df %&gt;%
  filter(Year_level == 3) %&gt;%
  lm(Numeracy ~ 1 + Treatment + 
       First_Nations + Language_background + SES + Gender, 
     data = .) %&gt;%
  tidy() |&gt; 
  filter(str_detect(term, &quot;Treatment&quot;))</code></pre>
<div class="kable-table">
<table>
<thead>
<tr class="header">
<th align="left">term</th>
<th align="right">estimate</th>
<th align="right">std.error</th>
<th align="right">statistic</th>
<th align="right">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Treatment1</td>
<td align="right">-24.69</td>
<td align="right">3.033</td>
<td align="right">-8.139</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
</div>
<p>Including predictors of poor numeracy (e.g., SES, First_Nations,
Gender) reduces but does not remove the pre-existing difference between
treatment groups, consistent with enrolment of schools with poor
numeracy into the program.</p>
<p>Also note the higher proportion of minorities, lower SES regions and
males in the program schools, consistent with enrolment of schools with
poor numeracy into the program.</p>
<pre class="r"><code>df %&gt;%
  filter(Year_level == 3) %&gt;%
  group_by(Treatment) %&gt;%
  summarise(
    Numeracy = mean(Numeracy),
    First_Nations = mean(First_Nations),
    Language = mean(Language_background),
    SES = mean(SES),
    Females = mean(Gender))</code></pre>
<div class="kable-table">
<table>
<thead>
<tr class="header">
<th align="left">Treatment</th>
<th align="right">Numeracy</th>
<th align="right">First_Nations</th>
<th align="right">Language</th>
<th align="right">SES</th>
<th align="right">Females</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">0</td>
<td align="right">422.7</td>
<td align="right">0.0291</td>
<td align="right">0.1809</td>
<td align="right">1042</td>
<td align="right">0.4875</td>
</tr>
<tr class="even">
<td align="left">1</td>
<td align="right">391.5</td>
<td align="right">0.0993</td>
<td align="right">0.3216</td>
<td align="right">1038</td>
<td align="right">0.5160</td>
</tr>
</tbody>
</table>
</div>
<p><br></p>
<p>Given the pre-existing differences in numeracy between groups, a
second important assumption of the model is the impact of the program is
homogenous across levels of numeracy. That is, the model assumes there
are no heterogenous treatment effects between low and high levels of
numeracy. This can be tested by plotting Year 3 numeracy levels against
Year 4 numeracy levels for each student <a
href="https://www.researchgate.net/publication/10854793_Making_friends_with_your_data_Improving_how_statistics_are_conducted_and_reported">Wright
(2003)</a>. The vertical distance between these slopes in each panel
indicates the treatment effect. Where the slopes are not parallel
indicates the program may have a <em>heterogenous treatment effect</em>
across Year 3 numeracy levels.</p>
<div
id="figure-1.-association-between-year-3-pre-and-year-4-post-numeracy-for-program-and-non-program-groups"
class="section level4">
<h4>Figure 1. Association between Year 3 (pre) and Year 4 (post)
numeracy for program and non-program groups</h4>
<pre class="r"><code>wdf %&gt;%
  ggplot(aes(x = Pre, y = Post, color = Treatment, fill = Treatment)) +
    # geom_point(alpha = 0.6) +
    geom_smooth(method = &quot;lm&quot;, formula = y ~ x, se=T) +
    # scale_color_manual(values = c(blues9[5], blues9[9])) +
    scale_color_manual(aesthetics = c(&quot;fill&quot;, &quot;color&quot;), 
                       values = c(&quot;#377EB8&quot;, &quot;#E41A1C&quot;)) +
    labs(subtitle = &quot;Year 4 numeracy (red = program)&quot;,
         y = &quot;&quot;, x = &quot;Year 3 numeracy&quot;) +
    theme_minimal()</code></pre>
<p><img src="rcts_files/figure-html/wright_plot-1.png" width="672" /></p>
<p><br></p>
<p>The association between Year 3 and Year 4 numeracy is steeper for
program schools (in red) indicating heterogenous treatment effects may
be present, perhaps due to the program improving above average students
more than below average students.</p>
<p><br></p>
<p><br></p>
</div>
<div
id="what-are-some-limitations-andor-caveats-of-the-analysis-how-could-the-model-be-improved-to-overcome-some-of-these-limitations"
class="section level4">
<h4>What are some limitations and/or caveats of the analysis? How could
the model be improved to overcome some of these limitations?</h4>
<p>In the presence of pre-existing differences (without randomization),
it is not possible to conclude the program was effective on the basis of
comparisons between Year 4 scores of the program and non-program
schools. This is because of two reasons: 1) some of the difference in
Year 4 numeracy may have been due to the pre-existing differences in
Year 3 (the association between Year 3 and Year 4 numeracy scores was
<span class="math inline">\(\beta = 0.741\)</span>, <span
class="math inline">\(p &lt; .001\)</span> in Table 1 above); 2)
equating groups on Year 3 numeracy scores either by matching or
regression control will induce RTM effects (see above).</p>
<p>However it is still possible to determine whether program schools
<em>gain</em> more numeracy on average than schools not in the program
by the estimand of a gain score analysis. It is important to note that a
gain score analysis answers a distinctly different question from the
post score ANCOVA, namely whether program schools gain the same amount
of numeracy on average as the other schools. By contrast the ANCOVA
assesses the difference in post means after equating for pre
differences).</p>
<p>Below we estimate the relative gain of program schools over other
schools to determine whether more benefit accrued to the program schools
after treatment.</p>
<pre class="r"><code>cwdf &lt;- wdf |&gt; 
  mutate(Change = Post - Pre)</code></pre>
<p>The simplest gain score analysis is done with a t-test/OLS. The
unadjusted estimate is the difference between the mean differences, and
shows a much more profound improvement among program schools. This
produces an unbiased estimate however it does not account for the
expected dependency between students from the same school, and so does
not control the type-I error rate at the nominal level (i.e., the
p-value is too low).</p>
<pre class="r"><code>cwdf %&gt;%
  # recode so gain is over non-program schools:
  mutate(Treatment = fct_rev(Treatment)) %&gt;%
  t.test(Change ~ Treatment, data = .) %&gt;% 
  tidy() %&gt;%
  select(`0` = estimate2, `1` = estimate1, estimate:conf.high) </code></pre>
<div class="kable-table">
<table>
<colgroup>
<col width="8%" />
<col width="8%" />
<col width="13%" />
<col width="14%" />
<col width="11%" />
<col width="14%" />
<col width="13%" />
<col width="14%" />
</colgroup>
<thead>
<tr class="header">
<th align="right">0</th>
<th align="right">1</th>
<th align="right">estimate</th>
<th align="right">statistic</th>
<th align="right">p.value</th>
<th align="right">parameter</th>
<th align="right">conf.low</th>
<th align="right">conf.high</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">80.76</td>
<td align="right">90.26</td>
<td align="right">9.501</td>
<td align="right">4.937</td>
<td align="right">0</td>
<td align="right">1920</td>
<td align="right">5.727</td>
<td align="right">13.28</td>
</tr>
</tbody>
</table>
</div>
<p>The estimate <strong>9.501</strong> from the <em>t</em>-test is an
unbiased estimate, however the error term (and therefore the p-value
.000000862) does not respect the dependency between students within the
same school in the data.</p>
<p>To account for the dependency, we can adjust the error term over
schools rather than students in a nested linear model with blocked error
terms:</p>
<pre class="r"><code>aov(Change ~ 1 + Treatment + Error(School_ID), 
    data = cwdf) -&gt; aov.change.school 

aov.change.school %&gt;% 
  emmeans::emmeans(&quot;Treatment&quot;) %&gt;%
  as.data.frame() %&gt;%
  select(Treatment, emmean) %&gt;%
  spread(Treatment, emmean) %&gt;%
  mutate(estimate = `1` - `0`) </code></pre>
<pre><code>## Note: re-fitting model with sum-to-zero contrasts</code></pre>
<div class="kable-table">
<table>
<thead>
<tr class="header">
<th align="right">0</th>
<th align="right">1</th>
<th align="right">estimate</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">80.77</td>
<td align="right">90.28</td>
<td align="right">9.501</td>
</tr>
</tbody>
</table>
</div>
<p>The estimate <strong>9.501</strong> is equivalent to the t-test
result, but now the degrees of freedom (<strong>df = 47</strong>) is
consistent with the number of schools (n = 49) and so the p-value
(<strong>.018</strong>) is correctly adjusted.</p>
<p><br></p>
<p>To account for the dependency we can also estimate a random intercept
for each school in a linear mixed model (LMM):</p>
<pre class="r"><code>fit.2 &lt;- lmer(Change ~ 1 + Treatment + (1|School_ID),
     data = as.data.frame(cwdf))

fit.2 %&gt;%
  tidy(effects = &quot;fixed&quot;, conf.int=T) %&gt;%
  filter(term == &quot;Treatment1&quot;) </code></pre>
<div class="kable-table">
<table>
<colgroup>
<col width="8%" />
<col width="13%" />
<col width="11%" />
<col width="12%" />
<col width="12%" />
<col width="7%" />
<col width="10%" />
<col width="11%" />
<col width="12%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">effect</th>
<th align="left">term</th>
<th align="right">estimate</th>
<th align="right">std.error</th>
<th align="right">statistic</th>
<th align="right">df</th>
<th align="right">p.value</th>
<th align="right">conf.low</th>
<th align="right">conf.high</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">fixed</td>
<td align="left">Treatment1</td>
<td align="right">9.881</td>
<td align="right">3.822</td>
<td align="right">2.586</td>
<td align="right">48.12</td>
<td align="right">0.0128</td>
<td align="right">2.198</td>
<td align="right">17.56</td>
</tr>
</tbody>
</table>
</div>
<p>The estimate from the LMM of <strong>9.88 (3.82)</strong> is similar
(but not equivalent) to the t-test result. Nevertheless, the degrees of
freedom (<strong>48.1</strong>) and therefore the p-value
(<strong>.0128</strong>) reflects the unique amount of information
provided by each school (ICC = 0.076).</p>
<p><br></p>
<p>We can also estimate gain in a mixed 2 x (2) ANOVA with treatment and
time (Pre, Post) as factors, where the interaction term
(<code>Time:Treatment</code>) represents the average gain of the program
schools over the other schools.</p>
<p>In a RM ANOVA, <code>Time</code> is nested within <code>School</code>
and this must be entered into the error term. Note the result matches
the nested ANOVA on the change scores:</p>
<pre class="r"><code>lpdf &lt;- df %&gt;%
  filter(Year_level %in% 3:4) %&gt;%
  mutate(Time = Year_level - 3) 

aov.interact.school &lt;- aov(Numeracy ~ Treatment*Time + Error(School_ID/Time),
                           data = lpdf) 

emmeans::emmeans(aov.interact.school,  ~ Time|Treatment) %&gt;%
  as.data.frame() %&gt;%
  select(Time, Treatment, emmean) %&gt;%
  spread(Time, emmean) %&gt;%
  mutate(delta = `1` - `0`) %&gt;%
  select(Treatment, delta) %&gt;%
  spread(Treatment, delta) %&gt;%
  mutate(estimate = `1` - `0`) </code></pre>
<pre><code>## Note: re-fitting model with sum-to-zero contrasts</code></pre>
<pre><code>## Warning in (mth$objs[[1]])(object, trms, xlev, grid, ...): Some predictors are correlated with
## the intercept - results may be very biased</code></pre>
<div class="kable-table">
<table>
<thead>
<tr class="header">
<th align="right">0</th>
<th align="right">1</th>
<th align="right">estimate</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">80.76</td>
<td align="right">90.26</td>
<td align="right">9.501</td>
</tr>
</tbody>
</table>
</div>
<p>The estimate (<strong>9.501</strong>), degrees of freedom
(<strong>47</strong>) and p-value (<strong>.018</strong>) exactly match
the nested linear model of change scores above.</p>
<p><br></p>
<p>Testing the same estimate in a linear mixed model setting, where the
interaction term (<code>Time:Treatment</code>) represents the gain of
program schools over other schools:</p>
<pre class="r"><code>fit.3 &lt;- df %&gt;%
  filter(Year_level %in% 3:4) %&gt;%
  mutate(Time = Year_level - 3) %&gt;%
  as.data.frame() %&gt;%
  lmer(Numeracy ~ 1 + Time*Treatment + (1|School_ID/Time),
       data = .) 

fit.3 %&gt;%
  tidy(effects = &quot;fixed&quot;, conf.int = T) %&gt;%
  filter(term == &quot;Time:Treatment1&quot;) </code></pre>
<div class="kable-table">
<table>
<colgroup>
<col width="8%" />
<col width="18%" />
<col width="10%" />
<col width="11%" />
<col width="11%" />
<col width="7%" />
<col width="9%" />
<col width="10%" />
<col width="11%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">effect</th>
<th align="left">term</th>
<th align="right">estimate</th>
<th align="right">std.error</th>
<th align="right">statistic</th>
<th align="right">df</th>
<th align="right">p.value</th>
<th align="right">conf.low</th>
<th align="right">conf.high</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">fixed</td>
<td align="left">Time:Treatment1</td>
<td align="right">9.512</td>
<td align="right">4.006</td>
<td align="right">2.374</td>
<td align="right">52.23</td>
<td align="right">0.0213</td>
<td align="right">1.474</td>
<td align="right">17.55</td>
</tr>
</tbody>
</table>
</div>
<p>The LMM with nested groups for school and time produces an estimate
similar to the t-test and RM ANOVA on gain scores: <strong>9.51
(±4.01)</strong>. Compared to the LMM on gain scores, this estimate has
more degrees of freedom (52.2 vs 48.1) and more residual random variance
(3780 vs 1650), because it is trying to explain two time points rather
than a single difference score.</p>
<p><br></p>
<p>Note that adding further controls (e.g., Year 3 numeracy scores) to
the gain score models will reintroduce RTM effects, as the model will
now be comparing gains among students from each group with the same Year
3 numeracy score, which will be above average for the treatment group
and below average for the control group.</p>
<pre class="r"><code># The effect of equating Year 3 numeracy scores on predicted gain
p1 &lt;- ggpredict(fit.2, terms = &quot;Treatment&quot;) %&gt;% plot() +
  coord_cartesian(ylim = c(75, 95)) +
  labs(subtitle = &quot;without equating Year 3 numeracy&quot;)

# Nb. Adding cPre turns this model into the post scores ANCOVA
fit.2b &lt;- lmer(Change ~ 1 + Treatment + Pre + (1|School_ID),
     data = as.data.frame(cwdf)) # 3.29 (4.88)

p2 &lt;- ggpredict(fit.2b, terms = &quot;Treatment&quot;) %&gt;% plot() +
  coord_cartesian(ylim = c(75, 95)) +
  labs(subtitle = &quot;after equating Year 3 numeracy&quot;)

p1 + p2</code></pre>
<p><img src="rcts_files/figure-html/gains_controlled-1.png" width="672" /></p>
<p><br></p>
<p>Likewise, adding the Year 3 numeracy scores (<code>Pre</code>) as a
covariate on the RHS of the two-way ANOVAs is invalid since Pre is
already included on the LHS in the first level of Time.</p>
<p>In the context of a pseudoexperimental design such as this, the
consensus appears to be that covariates for pre-existing differences
should not be included in a gain score analysis, as equating these real
differences is likely to mask the total effects of the program (Twisk et
al, 2018; Dallal 2020). According to Pearl (2016), the decision rests on
where the Year 3 numeracy levels stand with respect to the program
allocation in a causal DAG. If the schools were allocated to the program
<em>because</em> of their low numeracy levels then equating for numeracy
levels and including them as a covariate may be warranted if we are
interested in the direct effect of the program. However if we are
interested in the total compensatory effect of the program among low
numeracy students (so poor numeracy stands as a mediator of the program
effect), then we should estimate the total effect of the program and not
adjust for pre-existing differences. We aren’t told in this example how
allocation to the program was performed, so the only reasonable
justification I can provide is that we should be interested in how much
the program improved numeracy among the disadvantaged schools, rather
than whether the program will improve numeracy among all schools on
average.</p>
<p>Also note that without random allocation to groups, any estimated
differences in gain may be due to pre-existing differences between the
program schools and the other schools rather than the program, or even
due to an interaction between the program and the schools (i.e., if the
program only works in the <em>kind</em> of schools in the program); and
so the estimand does not represent the <em>average</em> treatment effect
(<span class="math inline">\(\tau\)</span>). Nevertheless, an estimate
of the difference in slope may be an informative of the success of the
program (i.e., in <em>those</em> schools), especially when we have no
reason to expect program schools to gain on other schools without
treatment.</p>
<p><br></p>
<p><br></p>
</div>
<div
id="what-can-you-conclude-from-this-model-about-the-short-term-impact-of-the-program-on-student-numeracy-proficiency-after-one-year"
class="section level4">
<h4>What can you conclude from this model about the short-term impact of
the program on student numeracy proficiency after one year?</h4>
<p>If schools were placed in the program <em>because</em> they had lower
numeracy levels, then we cannot conclude anything about the average
treatment effect of the program. The post score ANCOVA treatment
estimate above may include RTM effects and produce a biased estimate.
However the gain score analyses and the two-way ANOVAs indicate the
program moderately improved numeracy among poor performing schools, with
the potential average improvement ranging between 1 or 2 points to more
than 17 points.</p>
<p>If allocation to the program was random, then the average treatment
effect of the program on Year 4 numeracy is small (4.126) but everything
from moderate positive effects (10.1432) to small negative effects
(-1.8192) are consistent with the data, including a zero effect (<span
class="math inline">\(p &gt; .05\)</span>).</p>
<p>Regarding other practical considerations: We don’t know if the effect
of treatment is interacting with any of the other predictor variables
(e.g., Year 3 numeracy, relative school growth or SES). Adding
interaction terms would help determine the presence of varying effects
of treatment and so better understand the conditions under which the
treatment works, which may help when planning wider implementation or
policy.</p>
<p><br></p>
<p><br></p>
</div>
</div>
</div>
<div id="task-2-investigation-of-long-term-impact-of-treatment"
class="section level2">
<h2>Task 2 Investigation of long-term impact of treatment</h2>
<p>You are going to undertake a statistical analysis to evaluate the
long-term impact of the program. To do this, the numeracy performance of
the student sample from Task 1 was tracked to Year 6. The annual
numeracy results from Year 3 to Year 6 for both treatment and control
groups are given in the data file “Year 3-6 numeracy.csv”. The data is
in long format meaning that a student has multiple rows of records.</p>
<p>Same demographic variables as in Task 1 (except relative school
growth) are recorded in the data file. Student IDs, School IDs and the
numeracy scores from Year 3 to Year 6 are also included. The
“Year_level” variable indicates which Year level the record comes
from.</p>
<p><br></p>
<div id="estimate-the-long-term-effect-of-treatment"
class="section level4">
<h4>Estimate the long-term effect of treatment</h4>
<p>The suggested solution to a similar design, albiet in the context of
an RCT, is offered by <a
href="https://doi.org/10.1186%2Fs13063-020-4114-9" target="_blank">Bell
&amp; Rabe, 2020</a>. Based on simulations of cluster randomized trial
data where the outcome was continuous and measured at baseline and three
post-intervention time points (as we have here) they suggested the
following model:</p>
<pre class="r"><code>library(nlme)
library(contrast)

# “treat” and “time” are factors with levels (0,1) and (0,1,2,3) respectively.

Model1 &lt;- lme(y ~ treat*time, 
    random = ~ 1 | cluster_id,
    weights = varIdent(form = ~ 1 | time),
    correlation = corSymm(form = ~ 1 | cluster_id/subject_id),
    data = dataset, control = lmeControl(maxIter=10000, msMaxIter = 10000))
summary(Model1)

# Note that this contrast does not use the Kenward-Roger correction for degrees
# of freedom which is not implemented in nlme.

contrast(Model1, list(time = &#39;3&#39;, treat = &#39;1&#39;), list(time = &#39;3&#39;, treat = &#39;0&#39;))</code></pre>
<p>This <strong>mixed model for repeated measures</strong> (MMRM) uses
an unstructured time and covariance structure. Unstructured time means
that time is modeled categorically, rather than continuously as a linear
or polynomial function, and allows for an arbitrary trajectory over
time. While the continuous time models may use fewer degrees of freedom
and may, therefore, be more powerful, it can be difficult to anticipate
the outcome’s time trajectory in advance. Since clinical trials often
require a pre-specified analysis plan, unstructured time can be
appealing. In the context of randomized controlled trials, fixed effects
of time, treatment and their interaction are included in the MMRM model.
The interaction term accommodates different patterns of change over time
between the arms. Baseline values of the outcome are sometimes included.
Maximum-likelihood-based mixed models provide unbiased estimation for
data that are MCAR or MAR, as long as the model is not misspecified. All
outcome data are used, regardless of whether an individual has complete
data or not, making these models consistent with an intention-to-treat
analysis.</p>
<p>Cluster randomized trials with longitudinally measured outcomes have
two sources of non-independence: the cluster and the repeated measures
over time. Linear mixed-effects models are one option for handling the
non-independence of measurements over time. In the mixed-model context,
one may use a random-coefficients model, using random effects for a
subject’s intercept and sometimes slope. Alternatively, one may use
covariance pattern models, where the covariance between repeated
measures on the same subject is modeled explicitly from the residual
effects. Some commonly used covariance structures, available in
statistical software, include compound symmetric, autoregressive, or
unstructured. A compound symmetric structure assumes that any two
measurements on the same individual have the same covariance, regardless
of timing. An autoregressive structure assumes that measurements’
correlation drops over time exponentially. Unstructured covariance makes
no assumptions about the correlation between measurements, thereby
rendering misspecification not a problem; however, it can require that a
large number of parameters must be estimated. However, many cluster
trials have a fairly small number of assessments on each subject, as we
have here.</p>
<p>This model is easily extended to include more than two arms, the
baseline value of the outcome variable as a covariate (instead of in the
outcome vector as shown here), and/or a baseline by treatment arm
interaction.</p>
<p>Our interest was the long-term effect of the program, so under an RCT
assumption we could ignore pre-existing differences at baseline (Time 0)
and focus on the difference at the fourth time point between the
treatment arms, which can be estimated using a contrast within the
model.</p>
<pre class="r"><code>library(nlme)
library(ggeffects)

fit.9 &lt;- df %&gt;% 
  mutate(Time = as.factor(Year_level - 3),
         # Treatment = fct_rev(Treatment),
         Student_ID = as.factor(Student_ID)) %&gt;%
  as.data.frame() %&gt;%
  lme(Numeracy ~ 1 + Time*Treatment,
       random = ~1 | School_ID,
       weights = varIdent(form = ~ 1 | Time),
       correlation = corSymm(form = ~ 1 | School_ID/Student_ID),
       data = ., control = lmeControl(maxIter=10000, msMaxIter = 10000))</code></pre>
<pre class="r"><code>ggpredict(fit.9, terms = c(&quot;Time&quot;, &quot;Treatment&quot;)) %&gt;% 
  plot()</code></pre>
<p><img src="rcts_files/figure-html/mmrm_plot-1.png" width="672" /></p>
<p><br></p>
<pre class="r"><code>hypothesis_test(fit.9, c(&quot;Time [3]&quot;, &quot;Treatment&quot;))</code></pre>
<div class="kable-table">
<table>
<thead>
<tr class="header">
<th align="left">Time</th>
<th align="left">Treatment</th>
<th align="right">Contrast</th>
<th align="right">conf.low</th>
<th align="right">conf.high</th>
<th align="right">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">3-3</td>
<td align="left">0-1</td>
<td align="right">4.827</td>
<td align="right">-10.86</td>
<td align="right">20.52</td>
<td align="right">0.5389</td>
</tr>
</tbody>
</table>
</div>
<p>The estimate of the difference between treatment arms in the fourth
year (Time 3), after adjusting for pre-existing differences at Time 0
was <strong>4.83 [-10.86, 20.52]</strong>, <em>p</em> = .5.</p>
<p><br></p>
<p>However if we relax the RCT assumption, we can compare the total
long-term gain in numeracy between program and non-program schools:</p>
<pre class="r"><code>predict_response(fit.9, terms = c(&quot;Time&quot;, &quot;Treatment&quot;)) %&gt;%
  test_predictions(test = &quot;interaction&quot;) |&gt; 
  slice(3)</code></pre>
<div class="kable-table">
<table>
<thead>
<tr class="header">
<th align="left">Time</th>
<th align="left">Treatment</th>
<th align="right">Contrast</th>
<th align="right">conf.low</th>
<th align="right">conf.high</th>
<th align="right">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">0-3</td>
<td align="left">0 and 1</td>
<td align="right">24.84</td>
<td align="right">20.54</td>
<td align="right">29.14</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
</div>
<p>The estimate of the difference in total growth among program schools
over non-program schools in the fourth year is <strong>24.84 [20.54,
29.14]</strong>, <em>p</em> &lt; .001.</p>
<p><br></p>
<p><br></p>
<p>Beyond the MMRM, a linear mixed model with a linear effect of time
can test an interaction model, similar to the two-way ANOVA in Task 1,
which will determine the (average) gain per year among program schools
relative to other schools, over Years 3 to 6:</p>
<pre class="r"><code>fit.5 &lt;- lmer(Numeracy ~ Treatment*Year_level + (1|School_ID/Year_level),
              data = df)

tidy(fit.5, effects = &quot;fixed&quot;, conf.int=T) %&gt;%
  filter(term == &quot;Treatment1:Year_level&quot;)</code></pre>
<div class="kable-table">
<table>
<colgroup>
<col width="7%" />
<col width="24%" />
<col width="9%" />
<col width="10%" />
<col width="10%" />
<col width="6%" />
<col width="8%" />
<col width="9%" />
<col width="10%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">effect</th>
<th align="left">term</th>
<th align="right">estimate</th>
<th align="right">std.error</th>
<th align="right">statistic</th>
<th align="right">df</th>
<th align="right">p.value</th>
<th align="right">conf.low</th>
<th align="right">conf.high</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">fixed</td>
<td align="left">Treatment1:Year_level</td>
<td align="right">8.383</td>
<td align="right">1.85</td>
<td align="right">4.53</td>
<td align="right">146.5</td>
<td align="right">0</td>
<td align="right">4.726</td>
<td align="right">12.04</td>
</tr>
</tbody>
</table>
</div>
<pre class="r"><code># adding covariates does not change this estimate (8.38±1.85 vs 8.38±1.85)

lmer(Numeracy ~ Treatment*Year_level + SES + Gender + First_Nations + 
       Language_background + (1|School_ID/Year_level),
     data = df) %&gt;%
  tidy(effects = &quot;fixed&quot;) %&gt;%
  filter(term == &quot;Treatment1:Year_level&quot;) </code></pre>
<p>The interaction between <code>Treatment</code> and
<code>Year_level</code> indicates the long-term impact of the program
over other schools. The average relative gain of program schools from
Year 3 to Year 6 is <strong>8.38 [4.73, 12.0]</strong> points over other
schools. We can multiply this estimate by 3 to obtain the total growth
in the final year (26.52).</p>
<p><br></p>
<p><br></p>
<p>To determine the long-term effect of the program over any short-term
effect, we can omit Year 3 from the interaction and estimate the
relative gain from Year 4. Including the Year 3 scores as a (centered)
covariate will equate pre-existing differences in this model (and so
reintroduce RTM effects).</p>
<pre class="r"><code>left_join(df, 
          filter(df, Year_level==3) %&gt;% 
            select(School_ID, Student_ID, Pre = Numeracy),
          by = join_by(School_ID, Student_ID)) %&gt;%
  filter(Year_level &gt; 3) %&gt;%
  lmer(Numeracy ~ Treatment*Year_level + (1|School_ID/Year_level),
       data = .) -&gt; fit.6</code></pre>
<pre><code>## boundary (singular) fit: see help(&#39;isSingular&#39;)</code></pre>
<pre><code>## Warning: Model failed to converge with 1 negative eigenvalue: -3.0e+02</code></pre>
<pre class="r"><code>tidy(fit.6, effects = &quot;fixed&quot;, conf.int = T) %&gt;%
  filter(term == &quot;Treatment1:Year_level&quot;) </code></pre>
<div class="kable-table">
<table>
<colgroup>
<col width="7%" />
<col width="24%" />
<col width="10%" />
<col width="11%" />
<col width="11%" />
<col width="5%" />
<col width="8%" />
<col width="10%" />
<col width="11%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">effect</th>
<th align="left">term</th>
<th align="right">estimate</th>
<th align="right">std.error</th>
<th align="right">statistic</th>
<th align="right">df</th>
<th align="right">p.value</th>
<th align="right">conf.low</th>
<th align="right">conf.high</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">fixed</td>
<td align="left">Treatment1:Year_level</td>
<td align="right">7.669</td>
<td align="right">1.848</td>
<td align="right">4.149</td>
<td align="right">5736</td>
<td align="right">0</td>
<td align="right">4.046</td>
<td align="right">11.29</td>
</tr>
</tbody>
</table>
</div>
<p>After realising the short-term gains, the average long-term gain of
program schools in Year 4 to Year 6 was <strong>7.67 [4.05,
11.3]</strong> points year-to-year over other schools.</p>
<p><br></p>
<p>The long-term gain could also be represented by the total relative
gain between Year 3 to Year 6 for the program schools over the other
schools. To estimate this, we include Year_level as a dummy variable
rather than as a linear term.</p>
<pre class="r"><code>mutate(df, Year_level = factor(Year_level)) %&gt;%
  lmer(Numeracy ~ Treatment*Year_level + (1|School_ID/Year_level),
       data = .) -&gt; fit.8</code></pre>
<pre><code>## boundary (singular) fit: see help(&#39;isSingular&#39;)</code></pre>
<pre class="r"><code>tidy(fit.8, effects = &quot;fixed&quot;, conf.int = T) %&gt;%
  filter(str_detect(term, &quot;Treatment1:Year_level6&quot;)) %&gt;%
  select(-effect) </code></pre>
<div class="kable-table">
<table>
<colgroup>
<col width="27%" />
<col width="10%" />
<col width="11%" />
<col width="11%" />
<col width="5%" />
<col width="9%" />
<col width="10%" />
<col width="11%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">term</th>
<th align="right">estimate</th>
<th align="right">std.error</th>
<th align="right">statistic</th>
<th align="right">df</th>
<th align="right">p.value</th>
<th align="right">conf.low</th>
<th align="right">conf.high</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Treatment1:Year_level6</td>
<td align="right">24.84</td>
<td align="right">3.774</td>
<td align="right">6.581</td>
<td align="right">7661</td>
<td align="right">0</td>
<td align="right">17.44</td>
<td align="right">32.24</td>
</tr>
</tbody>
</table>
</div>
<p>This gives us the same estimate as the MMRM but with wider 95%CIs:
<strong>24.8 [17.5, 32.2]</strong>.</p>
<p><br></p>
<p><br></p>
</div>
</div>
</div>
<div id="rubin-1974" class="section level1">
<h1>Rubin 1974</h1>
<p>Causal inference, <em>aka</em> estimating the average treatment
effect (ATE, or <span class="math inline">\(\tau\)</span>), usually
requires random allocation to a treatment and a control group but not
always. The critical reference here is <a
href="https://scholar.google.com/scholar_lookup?hl=en&amp;volume=66&amp;publication_year=1974&amp;pages=688&amp;journal=Journal+of+Educational+Psychology&amp;author=D.+B.+Rubin&amp;title=“Estimating+Causal+Effects+of+Treatments+in+Randomized+and+Nonrandomized+Studies%2C”&amp;doi=10.1037%2Fh0037350">Rubin,
1974</a>, which is the fundamental reference in the field, along with
many modern representations of it (e.g., <a
href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5898524/">Twisk et al
2018</a>; <a
href="https://trialsjournal.biomedcentral.com/articles/10.1186/s13063-018-3108-3">Clifton
&amp; Clifton 2019</a>; <a
href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6290914/">O’Connell
et al 2017</a>).</p>
<p><br></p>
<p>Randomization guarantees that any pre-existing differences between
groups are non-systematic, so the estimand <span
class="math inline">\(\tau\)</span> will be <strong>unbiased</strong> -
but potentially not very precise. Note that <em>unbiased</em> does not
require random sampling from a broader population or any other
assumption here (although generalizability might). And it only
guarantees <em>unbiased</em> in the long run, as a hidden confound could
(randomly) occur in any particular random draw.</p>
<p>While randomization guarantees that pre-existing differences are not
systematic, it is not the only way to <em>deal</em> with pre-existing
differences. We can also <strong>match</strong> groups on the important
causal variables to remove (or reduce) pre-existing differences. This is
different from randomization which can leave pre-existing differences
between groups, because it removes/reduces the differences and so will
also produce more precise causal estimates. In practice we rarely have a
“complete &amp; true” causal model to guarantee we have removed the
pre-existing differences, and so is the reason we rely on randomization
as it does not depend upon our prior knowledge.</p>
<p>We can match groups by selecting matched pairs, or we can also add
the pre-existing variable as a covariate to our model (e.g., ANCOVA).
The ANCOVA determines the effect of each variable holding the other
covariates at the same value (e.g., 0). When these other covariates
represent pre-existing differences it is similar (but not equivalent?)
to matching.</p>
<p>In nonrandomized designs we do not always want to match pre-existing
differences (!!). In <strong>Lord’s Paradox</strong>, a dietician wanted
to know how the school cafeteria diet affected weight gain among boys
and girls. Pre and post weights were measured at the beginning and end
of term respectively. There were pre-existing differences since boys
were generally heavier than girls at the beginning of term, and there
were also post differences as these pre differences tended to carry over
(plus any differential diet effects). Adding the initial pre weights as
a covariate (i.e., ANCOVA on post weights) will determine whether the
post weights differed between boys and girls with identical frequency
distributions of initial weight. However when equating boys and girls by
the same pre weight, one is selecting relatively light boys and
relatively heavy girls. Under <em>regression-to-the-mean</em>, those
light boys will end up gaining more weight and the heavy girls will end
up gaining less weight, even without any impact of dining hall diet.
Thus when groups are equated, one group appears to be affected by diet
more than the other, using either post weights or weight gain (post -
pre). The important point to draw is that equating for pre-existing
differences is not always pertinent to the research question and can
also produce biased estimates (by introducing RTM effects).</p>
<p><a href="https://en.wikipedia.org/wiki/Lord&#39;s_paradox">Pearl
(2016)</a> provides a succinct explanation for the different estimates
produced by covariate adjustment of pre scores, according to the
difference between direct and total effects. In a causal model of Lords
Paradox, initial weight is a mediating variable of the effect of sex on
final weight (i.e., Sex -&gt; Initial Weight -&gt; Final Weight). Thus
including initial weight as a covariate estimates the <em>direct
effect</em> of sex on final weight (or weight gain). Conversely,
omitting initial weight then estimates the <em>total effect</em> of sex
on final weight. The appropriate estimate (and therefore estimand)
depends on the research question at hand.</p>
<p>In general, the <span class="math inline">\(\tau\)</span> in an RCT
can be estimated from post or gain scores, as pre-existing differences
are random (as are RTM effects) and therefore the estimate is unbiased,
however including pre scores as a covariate in an ANCOVA is always more
efficient (Rubin, 1974). On the other hand, when <a
href="http://www.jerrydallal.com/lhsp/prepost.htm">assignment is not
random and experimental groups are defined by a variable that is
relevant to the change in measurement, then gain scores without
covariate adjustment for pre score differences usually produce a more
relevant estimand</a>.</p>
<pre><code># From Dorothy Bishop https://doi.org/10.1177/25152459241267904
Analyses of intervention effects conducted in schools can be affected by clustering if randomization is conducted at the level of the schools or classrooms because children within a school/classroom are likely to be more similar to each otherthan to children from different schools/classrooms. Standard errors and p-values from a typical regression model depend on the assumption that the residuals in the model across cases are independent from each other. If children within classrooms are more similar to each other, the assumption of independence of residuals is violated, and this will usually reduce the precision of confidence intervals (and hence reduce the statistical significance of effects).  

The key statistic for any analysis that seeks to control for the effects of clusters is the intracluster correlation coefficient (ICC). The ICC is the proportion of total variance in a dependent variable explained by the cluster variable. So an ICC of 0.15 means the 15% of the variance in scores can be explained by the cluster variable. Typically ICCs greater than 0.10 are considered likely to have significant effects on standard errors. 

If so then we could include school as a fixed effect with an HC1 or HC2 adjustment.</code></pre>
<p><br></p>
<p><br></p>
</div>
<div id="takeaways" class="section level1">
<h1>Takeaways</h1>
<p>In general gain score analyses answer a distinctly different question
from ANCOVA, namely “Do subjects in the treatment group gain more than
subjects in the control group?”, which is more appropriate when trying
to understand the compensatory effects of a treatment or randomization
is not present.</p>
<p>Use ANCOVA (with or without change scores) with random allocation to
treatment groups (RCT) when estimating <span
class="math inline">\(\tau\)</span>.</p>
<p>Without random allocation, use change scores to estimate gain (and
ANCOVA may be vulnerable to RTM).</p>
<p>Equating pre-existing differences is not always a good idea and can
produce bias in some causal effects (e.g., when the groups are the
reason for the pre-existing difference in Y)</p>
<p>When to use change-from-baseline (CFB or gain scores)<br />
<img src="PREvPOST.png" /></p>
<p><br></p>
<p><br></p>
</div>
<div id="not-run" class="section level1">
<h1>Not run</h1>
<pre class="r"><code>fit.1 &lt;- lmer(Post ~ 1 + Treatment + Pre + (1|School_ID),
              data = as.data.frame(wdf)) 

tidy(fit.1, effects = &quot;fixed&quot;) %&gt;%
  filter(term == &quot;Treatment1&quot;) # 3.29 (4.88) vs 4.126 (3.070)

# The estimated impact of the program on Year 4 numeracy scores from the ANCOVA
# was **3.29 (±4.88)** points after equating for Year 3 numeracy level. This
# estimate is similar to that provided in Table 1 above (**4.126 ±3.07**).  
# 
# Adding additional covariates such as gender etc improves the precision of the
# estimate but not enough to change the null result.  </code></pre>
<pre class="r"><code># Adding covariates to equate for pre-existing differences does not change the
# location of the estimate, but does slightly improve the precision
mutate(df, Year_level = factor(Year_level)) %&gt;%
  lmer(Numeracy ~ Treatment*Year_level + SES + Gender + 
         First_Nations + Language_background + (1|School_ID/Year_level),
       data = .) -&gt; fit.9

tidy(fit.9, effects = &quot;fixed&quot;) %&gt;%
  filter(str_detect(term, &quot;Treatment1:&quot;)) %&gt;%
  select(-effect) # 24.8 (3.72)</code></pre>
<pre class="r"><code>p1 &lt;- ggpredict(fit.8, terms = c(&quot;Year_level&quot;, &quot;Treatment&quot;)) %&gt;% plot() +
  labs(subtitle = &quot;without adjustment&quot;)

p2 &lt;- ggpredict(fit.9, terms = c(&quot;Year_level&quot;, &quot;Treatment&quot;)) %&gt;% plot() +
  labs(subtitle = &quot;with adjustment&quot;)

p1 + p2 + plot_layout(guides = &#39;collect&#39;) &amp; 
  theme(legend.position = &quot;bottom&quot;)</code></pre>
<p><br></p>
<pre class="r"><code># Assuming a smooth effect of time
mutate(df, Treatment = ordered(Treatment)) %&gt;%
  gamm(Numeracy ~ Treatment +s(Year_level, k = 4) + 
         s(Year_level, by = Treatment, k = 4),
       correlation = corAR1(form = ~1|School_ID),
       data = .) -&gt; fit

ggpredict(fit$gam, terms = c(&quot;Year_level&quot;, &quot;Treatment&quot;)) %&gt;% plot()



plot(fit$gam, scale=0, shade=T, select=2, seWithMean=T)
abline(h=0, lty = 2)</code></pre>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
